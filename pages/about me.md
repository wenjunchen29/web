---
layout              : page-fullwidth
title               : "About me"
# subheadline         : "ToDo-List &amp; Ideas"
teaser              : "Keywords: AI voice-cloning; Speaker identity; Vocal confidence; AI-generated avatar; Learning; EEG; fMRI"
header:
   image_fullwidth  : "header_roadmap_3.jpg"
permalink           : "/about me/"
toc: true

---
I’m a second-year postgraduate (2/3 years) student at the Institute of Linguistics, Shanghai International Studies University. I opted for speech prosody-related psycho- and neuro-linguistics as my research domain for this linguistics degree but didn’t confine my effort only here. For my current Master’s degree, I am conducting a list of research to understand social cognition, particularly when language as a bond in either human-human interaction (HHI) or human-robot interaction (HRI) is involved in the era of algorithms. Among many social cognition domains, I am currently studying speaker identity, namely, ‘who is talking’? My postgraduate dissertation is to explore the neuro-correlates of human listeners’ learning and recognise the identity of the speakers they had been trained to familiarise. Here, the influence of the variable - speakers’ group identity being human or AI-generated speakers will be studied. This website is thus to introduce my endeavours and achievements throughout this academic quest. 

As a foundation, I have prepared audio clips by both humans and the corresponding AI-cloned speakers; altogether, 24 speakers * 2 sources being human or AI * 219 sentences * 3 confidence levels being confident, doubtful or neutral = 31,356 sentences in wav form. First thing first, I need to ensure the comparability of speech by human and AI speakers in terms of speaker identity and vocal confidence. I am validating the success of the AI algorithm’s speaker identity through a technique - speaker embedding that extracts a vector representation from a speech signal that captures the speaker identity of each speaker and presents them in a 2-D plotting. I am confirming AI’s capacity to clone not only speaker identity but also human-specific vocal confidence that carries pragmatic intention through a combination of studies: acoustic analysis and machine learning classification; for this, I have incorporated the findings into a prepared manuscript and will post it for peer-review soon. 

With the validated human and AI voices, I move to social cognition by naive human listeners, which is to be performed from May 2023 to May 2024. Firstly, how do speech prosodies mediate people’s perception of AI and human voices? This is to be reflected in the behavioural responses on the 7-Likert scale. I will be circling around ‘speaker identity’ and performing two studies. So, secondly, do people process human and AI identities in a similar manner? This is to be answered with the classic AxB paradigm while also taking prosodies into account. Then it comes to my dissertation, in which I will employ the training-testing paradigm, where listeners would learn the identity of a specific speaker and be tested on their learning outcomes. Here, I will use data from the electroencephalogram (EEG) to perform ERP analysis, source localisation, time-frequency analysis, and possibly entrainment analysis. 

Since I’m currently working on only the modality of auditory, I do value the possibility of moving to multimodality. And this leads me to my initial interest in AI-generated human avatars, which has been seen and expected to see, thanks to the prevalence of the game changer - ChatGPT, increasing applications in our human society. But less is known about what challenges it might bring to human beings’ social cognition patterns in social interaction. Also, I suppose exposures and interactions, as two learning engagements, might play a part that shapes’ a human being’s specific social cognition of these avatars. Yet, these are merely preliminary thoughts subject to changes and await experimental evidence and theoretical support. 

Click for my CV, biography, and more details about my current lab affiliation and research interests publications.


---
